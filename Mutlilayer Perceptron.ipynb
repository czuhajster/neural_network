{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ee7cf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "    \"\"\"Object representing perceptron with two inputs.\n",
    "\n",
    "    Attributes:\n",
    "        e: A training set.\n",
    "        w0: Bias weight.\n",
    "        w1: The weight of the first input.\n",
    "        w2: The weight of the second input.\n",
    "        epochs: Number of epochs before stabilisation.\n",
    "    \"\"\"\n",
    "    def __init__(self, e, activation_function = lambda s: 1 if s > 0 else -1):\n",
    "        '''Initialises Perceptron object.'''\n",
    "        self.w0 = 0\n",
    "        self.w1 = 0\n",
    "        self.w2 = 0\n",
    "        self.e = e\n",
    "        self.activation_function = activation_function\n",
    "\n",
    "    def train(self):\n",
    "        \"\"\"Trains perceptron.\"\"\"\n",
    "        self.epochs = 1\n",
    "        stable = False\n",
    "        while not stable:\n",
    "            stable = True\n",
    "            for example in self.e:\n",
    "                print(example)\n",
    "                if self.classify(example[1], example[2]) == example[3]:\n",
    "                    pass\n",
    "                else:\n",
    "                    self.w0 += example[3] * example[0]\n",
    "                    self.w1 += example[3] * example[1]\n",
    "                    self.w2 += example[3] * example[2]\n",
    "                    stable = False\n",
    "            if not stable:\n",
    "                self.epochs += 1\n",
    "\n",
    "    def classify(self, x1, x2):\n",
    "        \"\"\"Classifies an object.\"\"\"\n",
    "        s = (self.w1 * x1) + (self.w2 * x2) + self.w0\n",
    "        return self.activation_function(s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9b98555",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9018c52",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e63732b9",
   "metadata": {},
   "source": [
    "### Sigmoid Function\n",
    "\n",
    "#### First Order Derivative\n",
    "\n",
    "We also need to calculate the first order differential of the function.\n",
    "\n",
    "$$\n",
    "f'(S_j) = u_j (1 - u_j)\n",
    "$$\n",
    "\n",
    "#### Delta Values\n",
    "\n",
    "- $\\delta_j = (C - u_O) f'(S_O)$ O is the output node.\n",
    "- $\\delta_j = w_{j,O} \\delta_O f'(S_j)$ for hidden layer nodes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a10c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9933071490757153"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Sigmoid:\n",
    "    \"\"\"Represents Sigmoid activation function.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialises a sigmoid object.\n",
    "        \"\"\"\n",
    "        self.vectorised_func = np.vectorize(self.func)\n",
    "        self.vectorised_der = np.vectorize(self.der)\n",
    "        \n",
    "    def func(self, x):\n",
    "        \"\"\"Calculates output of the Sigmoid function.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.e ** (-x))\n",
    "    \n",
    "    def der(self, x):\n",
    "        \"\"\"Calculates output of the derivative of the Sigmoid function.\n",
    "        \"\"\"\n",
    "        return self.func(x) * (1 - self.func(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a442fee1",
   "metadata": {},
   "source": [
    "### Tanh\n",
    "\n",
    "#### First Order Derivative\n",
    "\n",
    "$$\n",
    "f'(S_j) = 1 - u^2_j\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dcc56a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains definition of a layer of a neural network.\n",
    "\"\"\"\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "X = [[1, 2, 3, 2.5],\n",
    "     [2.0, 5.0, -1.0, 2.0],\n",
    "     [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "class Layer:\n",
    "    \"\"\"Layer of a neural network.\n",
    "    \n",
    "    Attributes:\n",
    "        weights: set of weights of the layer.\n",
    "        biases: set of biases of the layer.\n",
    "        activation_function: Activation Function of the layer.\n",
    "        number_of_inputs: Number of inputs coming to the layer.\n",
    "        number_of_inputs: Number of inputs coming to the layer.\n",
    "        output: the most recent output of the layer.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 number_of_inputs: int,\n",
    "                 number_of_neurons: int,\n",
    "                 activation_function\n",
    "                ):\n",
    "        \"\"\"Initialises a NeuralNetwork instance.\n",
    "        \"\"\"\n",
    "        self.number_of_neurons = number_of_neurons\n",
    "        self.activation_function = activation_function\n",
    "        random_generator = np.random.default_rng(5)\n",
    "        #NNFS self.weights = 0.01 * np.random.randn(n_inputs, n_neurons)\n",
    "        low = -2 / number_of_neurons\n",
    "        high = 2 / number_of_neurons\n",
    "        self.weights = random_generator.uniform(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            size=(number_of_inputs, number_of_neurons)\n",
    "        )\n",
    "        self.biases = random_generator.uniform(\n",
    "            low=low,\n",
    "            high=high,\n",
    "            size=(1, number_of_neurons)\n",
    "        )\n",
    "    \n",
    "    def forward_pass(self, inputs: np.ndarray):\n",
    "        \"\"\"Does the forward pass through the layer.\n",
    "        \n",
    "        Arguments:\n",
    "            inputs: Inputs to the layer.\n",
    "        \"\"\"\n",
    "        self.sum = np.dot(inputs, self.weights) + self.biases\n",
    "        self.output = self.activation_function.func(self.sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a398d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HiddenLayer(Layer):\n",
    "    \"\"\"Hidden Layer of a neural network.\n",
    "    \n",
    "    Attributes:\n",
    "        weights: set of weights of the layer.\n",
    "        biases: set of biases of the layer.\n",
    "        activation_function: Activation Function of the layer.\n",
    "        number_of_inputs: Number of inputs coming to the layer.\n",
    "        number_of_neurons: Number of neurons in the layer.\n",
    "        output: the most recent output of the layer.\n",
    "        delta: Delta value (output of the backward pass) of the layer.\n",
    "    \"\"\"\n",
    "    \n",
    "    def backward_pass(self, output_weights, output_delta):\n",
    "        \"\"\"Does the backward pass through the layer.\n",
    "        \n",
    "        Args:\n",
    "            y: Correct output (label) of the training example.\n",
    "        \"\"\"\n",
    "        self.delta = self.activation_function.der(self.sum) * output_delta * output_weights\n",
    "        \n",
    "        \n",
    "        \n",
    "layer1 = Layer(4, 5, sigmoid_vectorised)\n",
    "layer2 = Layer(5, 2, sigmoid_vectorised)\n",
    "\n",
    "layer1.forward_pass(X)\n",
    "#print(layer1.output)\n",
    "layer2.forward_pass(layer1.output)\n",
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9364fae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputLayer(Layer):\n",
    "    \"\"\"Single-node output layer of a neural network.\n",
    "    \n",
    "    Attributes:\n",
    "        weights: set of weights of the layer.\n",
    "        biases: set of biases of the layer.\n",
    "        activation_function: Activation Function of the layer.\n",
    "        number_of_inputs: Number of inputs coming to the layer.\n",
    "        number_of_neurons: Number of neurons in the layer.\n",
    "        output: the most recent output of the layer.\n",
    "        delta: Delta value (output of the backward pass) of the layer.\n",
    "    \"\"\"\n",
    "        \n",
    "    def backward_pass(self, y):\n",
    "        \"\"\"Does the backward pass through the layer.\n",
    "        \n",
    "        Args:\n",
    "            y: Correct output (label) of the training example.\n",
    "        \"\"\"\n",
    "        self.delta = (y - self.output) * self.activation_function.der(self.sum)\n",
    "        \n",
    "        \n",
    "        \n",
    "layer1 = Layer(4, 5, sigmoid_vectorised)\n",
    "layer2 = Layer(5, 2, sigmoid_vectorised)\n",
    "\n",
    "layer1.forward_pass(X)\n",
    "#print(layer1.output)\n",
    "layer2.forward_pass(layer1.output)\n",
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab3e65c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92fbb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains NeuralNetwork class definition.\n",
    "\n",
    "Run after running the Data Preprocessing notebook.\n",
    "\"\"\"\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \"\"\"A neural network with single hidden layer and single node on outputlayer.\n",
    "    \n",
    "    Attributes:\n",
    "        shape: Shape of the network (list of integers). Elements of the list\n",
    "            represent layers and the integer stand for number of nodes on\n",
    "            the layer.              \n",
    "        training_set: Set that instance is to be trained on.\n",
    "        test_set: Set that instance is to be tested on.\n",
    "        activation_functions: List of activation function used for\n",
    "            the neural network.\n",
    "        step_size: Step size parameter.\n",
    "        weights: Weights for hidden layer.\n",
    "        biases: Biases for hidden layer.\n",
    "        layers: List of network's layers (excluding input layer).\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        shape: list,\n",
    "        training_set: np.ndarray,\n",
    "        test_set: np.ndarray,\n",
    "        activation_functions: [Callable],\n",
    "        step_size: float = 0.1\n",
    "    ):\n",
    "        \"\"\"Initialises a NeuralNetwork instance.\n",
    "        \"\"\"\n",
    "        # TODO: Assign param values to the attributes.\n",
    "        # TODO: Assign **random** small weights and biases to all cells.\n",
    "        # TODO: Choose a small step size parameter (0.1).\n",
    "        \n",
    "        # Input is a matrix where each row is one instance\n",
    "        self.shape = shape\n",
    "        self.training_set = training_set\n",
    "        self.test_set = test_set\n",
    "        self.step_size = step_size\n",
    "        self.layers = []\n",
    "        for i in range(len(self.shape)):\n",
    "            # If this is first hidden layer, set number of inputs\n",
    "            # to the number of inputs to the network.\n",
    "            if i == 0:\n",
    "                number_of_inputs = self.test_set.shape[1]\n",
    "            else:\n",
    "                number_of_inputs = self.layers[i-1].number_of_neurons\n",
    "            number_of_neurons = self.shape[i]\n",
    "            layer = Layer(number_of_inputs, number_of_neurons, sigmoid_vectorised)\n",
    "            self.layers.append(layer)\n",
    "        \n",
    "    \n",
    "    \n",
    "    def train(self):\n",
    "        \"\"\"Trains NeuralNetwork instance.\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            for item, c in self.training_set:\n",
    "                # Make forward pass through the network. Compute\n",
    "                # - weighted sums\n",
    "                # - S_j\n",
    "                # - activations u_j = f(s_j) for every node\n",
    "                self.forward_pass(item)\n",
    "                self.backward_pass(c)\n",
    "                # backward pass though the network.\n",
    "                # Update the weights.\n",
    "                # output = np.dot(weights, inputs) + biases\n",
    "            \n",
    "    def forward_pass(self, inputs):\n",
    "        \"\"\"Performs forward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "        inputs: Vector of values represneting a training example.\n",
    "        \"\"\"\n",
    "        for i in range(len(self.layers)):\n",
    "            layer = self.layers[i]\n",
    "            if i == 0:\n",
    "                layer.forward_pass(inputs)\n",
    "            else:\n",
    "                layer.forward_pass(layers[i-1].output)\n",
    "                \n",
    "    \n",
    "    def backward_pass(self, c):\n",
    "        \"\"\"Performs backward pass through the network.\n",
    "        \n",
    "        Args:\n",
    "        c: The label for the training example.\n",
    "        \"\"\"\n",
    "        self.output_layer.backward_pass(c)\n",
    "        self.hidden_layer.backward_pass(\n",
    "            self.output_layer.weights,\n",
    "            self.output_layer.delta\n",
    "        )\n",
    "        for i, layer in reversed(list(enumerate(self.layers))):\n",
    "            if i == len(self.layers) - 1:\n",
    "                pass\n",
    "            else:\n",
    "                pass\n",
    "        \n",
    "        \n",
    "    def test(self):\n",
    "        \"\"\"Tests NeuralNetwork instance.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    def predict(self):\n",
    "        \"\"\"Predicts value for given predictor values.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9957936c",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = NeuralNetwork"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fb383da",
   "metadata": {},
   "source": [
    "## Batch Learning\n",
    "\n",
    "Batch size may improve efficiency. Showing all sampes at once can cause overfitting. It will be bad at generalsing.\n",
    "\n",
    "Typical batch size: 32\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17560591",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [[1, 2, 3, 2.5],\n",
    "          [2.0, 5.0, -1.0, 2.0],\n",
    "          [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "          [0.5, -.91, 0.26, -0.5],\n",
    "          [-0.26, -.27, 0.17, 0.87]]\n",
    "\n",
    "biases = [2, 3, 0.5]\n",
    "\n",
    "\n",
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "          [-0.5, 0.12, -0.33],\n",
    "          [-0.44, 0.73, -0.13]]\n",
    "\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(inputs, np.array(weights).T) + biases\n",
    "\n",
    "layer2_outputs = np.dot(layer1_outputs, np.array(weights2).T) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056ce84b",
   "metadata": {},
   "source": [
    "## Feature Data Set\n",
    "\n",
    "Feature data set is usaully denoted with `X`.\n",
    "\n",
    "Labels are usually denoted with `y`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cd882f",
   "metadata": {},
   "source": [
    "## Activation Functions\n",
    "\n",
    "Every node on hidden layers and output layer have an activation function.\n",
    "\n",
    "ReLU\n",
    "\n",
    "sigmoid func has gradient problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a931034",
   "metadata": {},
   "source": [
    "## Learning Rate\n",
    "\n",
    "Gradient of the error function\n",
    "\n",
    "Too small weights - stuck in local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c083cf",
   "metadata": {},
   "source": [
    "## New Weights\n",
    "\n",
    "$$\n",
    "w^*_{i,j} = w_{i,j} + \\rho \\delta_i u_i\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124ddfe7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
